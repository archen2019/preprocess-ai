{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to PyTuna!\n",
      "This short wizard will guide you through preprocessing your image data. For each field, you may press enter to fill it with the provided default value (the capitalized option).\n",
      "First, we need the path to the directory containing the image dataset you are classifying (default: \"dataset\"): ../datasets/captcha-version-2\n",
      "loading...\n",
      "\n",
      "Now, let's load the model which will predict what preprocessing steps to use. By default, we'll just use the model which comes prepackaged with this module (default: model.pb): \n",
      "\n",
      "Where do you want to load the model? The prepackaged model is quite large, so we recommend choosing cuda only if you have more than 11 GB of GPU ram. (default: cpu) cuda\n",
      "loading...\n",
      "predicting...\n",
      "\n",
      "Our model has predicted which preprocessing steps should be used. Now, let's walk you through each of its suggestions.\n",
      "\n",
      "\n",
      "Do you intend to apply transfer learning to a pre-trained model? (y/N): y\n",
      "\n",
      "Which model are you using? If the model doesn't appear in this list (vgg resnet alexnet squeezenet densenet inceptionv3 googlenet shufflenetv2 mobilenetv2 resnext wideresnet mnasnet), then type other (default: other): alexnet\n",
      "processing...\n",
      "\n",
      "Now that your images are resized, would you like to zero-center them? This will set the mean to 0 and standard deviation to 1 across each channel. This step could remove artifacts like a blue tint on every image. The model highly suggests this step. (Y/n) \n",
      "processing...\n",
      "\n",
      "Would you like to augment your data? This will create a copy of the entire dataset and apply random affine transforms to each image, which increases the size of the training data and lets your model learn more. Note that this will double the size of the dataset, and so you should append a copy of the list of label tensors to itself to accomodate the change. The model highly suggests this step. (Y/n) \n",
      "processing...\n",
      "\n",
      "Would you like to increase the contrast of the images in your dataset? This can lead to easier feature detection. The model does not suggest this step. (y/N) y\n",
      "processing...\n",
      "\n",
      "Would you like to histogram equalize your images? This will create a uniform distribution of grayscale values in each image. The model does not suggest this step. (y/N) \n",
      "\n",
      "Would you like to apply a Gaussian blur to your dataset? This will soften the edges in your images. The model highly suggests this step. (Y/n) \n",
      "processing...\n",
      "\n",
      "Would you like to grayscale your dataset? This will reduce the dimensionality of your dataset and could lead to faster convergence. The model does not recommend this step. (y/N) \n",
      "\n",
      "You could also try to remove the backgrounds in your dataset. While we can't do this manually, this step could remove noise and let the model learn about only the objects in the foreground for easier classification. The model does not recommend this step. (Press Enter to continue)\n",
      "\n",
      "You could also run an object detection algorithm on your dataset to make sure your model focuses on the objects contained in the images. Some popular options include YOLO and SSD. The model does not recommend this step. (Press Enter to continue) \n",
      "\n",
      "Would you like to save your preprocessed dataset to disk? This will create a new directory and populate it with pickled torch tensors representing each image. They can be loaded with torch.load('filename.pt') for future usage. If you choose not to, this function will still return a list of preprocessed tensors, ready for consumption by a model. (Y/n) \n",
      "\n",
      "What output directory would you like to save your preprocessed tensors to? (default: preprocessed_dataset) \n",
      "saving...\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess.preprocess_wizard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4280\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit3b532b7804ae44ebac946b2638348f62"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
